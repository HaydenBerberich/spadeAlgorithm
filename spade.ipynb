{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "wip1tcwcAfr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGSxyFEmAtzK",
        "outputId": "9f8be544-ae39-4719-d62a-35c0503dec8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV files into DataFrames\n",
        "aisles = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/aisles.csv')\n",
        "departments = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/departments.csv')\n",
        "order_products_prior = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/order_products__prior.csv')\n",
        "order_products_train = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/order_products__train.csv')\n",
        "orders = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/orders.csv')\n",
        "products = pd.read_csv('/content/drive/My Drive/instacart-market-basket-analysis/products.csv')"
      ],
      "metadata": {
        "id": "1fexq3T0Agpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines a function called reduce_memory_usage that aims to optimize the memory usage of a pandas DataFrame by converting its columns to more memory-efficient data types. The function iterates over each column in the DataFrame and checks its data type. If the column is not of type object (typically used for strings), it determines the minimum and maximum values in the column. Based on these values, it converts the column to the smallest possible integer or float type that can accommodate the range of values, thereby reducing memory usage. For example, if the column contains integer values that fit within the range of an int8, it converts the column to int8. Similarly, for floating-point numbers, it converts the column to float32 if the values fit within the range of a float32. After defining this function, the code applies it to several DataFrames (order_products_prior, order_products_train, orders, and products) to optimize their memory usage. This is particularly useful when working with large datasets, as it helps to reduce the overall memory footprint and improve performance."
      ],
      "metadata": {
        "id": "iaTBaFM1YEuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to reduce memory usage\n",
        "def reduce_memory_usage(df):\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > -128 and c_max < 127:\n",
        "                    df[col] = df[col].astype('int8')\n",
        "                elif c_min > -32768 and c_max < 32767:\n",
        "                    df[col] = df[col].astype('int16')\n",
        "                elif c_min > -2147483648 and c_max < 2147483647:\n",
        "                    df[col] = df[col].astype('int32')\n",
        "                else:\n",
        "                    df[col] = df[col].astype('int64')\n",
        "            else:\n",
        "                if c_min > -3.4e38 and c_max < 3.4e38:\n",
        "                    df[col] = df[col].astype('float32')\n",
        "                else:\n",
        "                    df[col] = df[col].astype('float64')\n",
        "    return df\n",
        "\n",
        "# Reduce memory usage\n",
        "order_products_prior = reduce_memory_usage(order_products_prior)\n",
        "order_products_train = reduce_memory_usage(order_products_train)\n",
        "orders = reduce_memory_usage(orders)\n",
        "products = reduce_memory_usage(products)"
      ],
      "metadata": {
        "id": "Al5lthbLA0Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code concatenates the order_products__prior and order_products__train DataFrames into a single DataFrame called order_products. It then performs a series of merges to enrich this DataFrame with additional details. First, it merges order_products with the orders DataFrame to include user and order details. Next, it merges the resulting DataFrame with the products DataFrame to add product details. Subsequently, it merges with the aisles DataFrame to incorporate aisle information, and finally, it merges with the departments DataFrame to include department details. After these merges, the code sorts the order_products DataFrame by user_id and order_number to ensure that the orders are processed in the correct sequence for each user."
      ],
      "metadata": {
        "id": "SdYF0wfPYWBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate order_products__prior and order_products__train\n",
        "order_products = pd.concat([order_products_prior, order_products_train])\n",
        "\n",
        "# Merge order_products with orders to get user and order details\n",
        "order_products = order_products.merge(orders, on='order_id', how='left')\n",
        "\n",
        "# Merge the resulting DataFrame with products to get product details\n",
        "order_products = order_products.merge(products, on='product_id', how='left')\n",
        "\n",
        "# Merge the resulting DataFrame with aisles to get aisle details\n",
        "order_products = order_products.merge(aisles, on='aisle_id', how='left')\n",
        "\n",
        "# Merge the resulting DataFrame with departments to get department details\n",
        "order_products = order_products.merge(departments, on='department_id', how='left')\n",
        "\n",
        "# Sort and group the merged data to ensure that you process the orders in the correct sequence for each user\n",
        "order_products = order_products.sort_values(by=['user_id', 'order_number'])"
      ],
      "metadata": {
        "id": "_tfmI2fIA6Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code performs several data preprocessing steps to prepare the dataset for analysis. First, it filters out users with very few transactions. It sets a minimum threshold of 5 transactions (min_transactions = 5) and calculates the number of transactions for each user using the value_counts method on the user_id column. It then identifies the users who meet or exceed this threshold and filters the order_products DataFrame to include only these valid users.\n",
        "\n",
        "Next, the code filters out items that appear infrequently. It sets a minimum item frequency threshold of 5 (min_item_frequency = 5) and calculates the number of occurrences for each product using the value_counts method on the product_id column. It identifies the products that meet or exceed this threshold and filters the order_products DataFrame to include only these valid items.\n",
        "\n",
        "To ensure that each transaction is unique for each user, the code removes duplicate entries by dropping rows with the same combination of user_id, order_id, and product_id using the drop_duplicates method.\n",
        "\n",
        "Finally, the code handles missing values by dropping any rows that contain missing values using the dropna method. These preprocessing steps help to clean and refine the dataset, ensuring that it is suitable for subsequent analysis."
      ],
      "metadata": {
        "id": "DECBAl8sYkhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out users with very few transactions\n",
        "min_transactions = 5\n",
        "user_order_counts = order_products['user_id'].value_counts()\n",
        "valid_users = user_order_counts[user_order_counts >= min_transactions].index\n",
        "order_products = order_products[order_products['user_id'].isin(valid_users)]\n",
        "\n",
        "# Filter out items that appear infrequently\n",
        "min_item_frequency = 5\n",
        "item_order_counts = order_products['product_id'].value_counts()\n",
        "valid_items = item_order_counts[item_order_counts >= min_item_frequency].index\n",
        "order_products = order_products[order_products['product_id'].isin(valid_items)]\n",
        "\n",
        "# Ensure each transaction is unique for each user by removing duplicates\n",
        "order_products = order_products.drop_duplicates(subset=['user_id', 'order_id', 'product_id'])\n",
        "\n",
        "# Handle missing values\n",
        "order_products = order_products.dropna()"
      ],
      "metadata": {
        "id": "F8-Tp_eqA-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines and implements the SPADE (Sequential Pattern Discovery using Equivalence classes) algorithm to discover frequent sequential patterns in transaction data.\n",
        "\n",
        "First, the generate_candidates function is defined to generate candidate sequences of a specified length. It takes the current frequent sequences and valid items, and creates new sequences by appending each valid item to the existing sequences, ensuring that the same item is not repeatedly added.\n",
        "\n",
        "Next, the count_support function is defined to count the support of each candidate sequence. It iterates through each candidate and each transaction, checking if the candidate sequence is present in the transaction. It maintains a count of how many transactions contain each candidate sequence. Progress is printed every 100 candidates or when the count reaches the total number of candidates.\n",
        "\n",
        "The prune_candidates function is then defined to prune candidate sequences that do not meet the minimum support threshold. It returns a dictionary of sequences that have support counts greater than or equal to the specified minimum support.\n",
        "\n",
        "The spade function implements the SPADE algorithm. It initializes an empty dictionary sequences to store frequent sequences and their support counts. It starts with sequences of length 1 and iteratively generates candidates of increasing lengths. For each length, it generates candidates, counts their support, prunes infrequent candidates, and updates the sequences dictionary with the pruned candidates. The process continues until no more candidates can be generated. The function returns a sorted list of frequent sequences and their support counts.\n",
        "\n",
        "The code then prepares the transactions for the SPADE algorithm by grouping the order_products DataFrame by user_id and creating a list of product IDs for each user.\n",
        "\n",
        "A minimum support threshold is defined as 20% of the total number of transactions.\n",
        "\n",
        "Finally, the SPADE algorithm is run with the prepared transactions and the minimum support threshold. The frequent patterns discovered by the algorithm are printed, excluding the empty sequence.\n",
        "\n",
        "This implementation helps to identify frequent sequential patterns in the transaction data, which can be useful for various analytical purposes, such as market basket analysis and recommendation systems."
      ],
      "metadata": {
        "id": "jwGIrcszY3sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate candidate sequences\n",
        "def generate_candidates(sequences, length):\n",
        "    candidates = set()\n",
        "    for seq in sequences:\n",
        "        for item in valid_items:\n",
        "            if item not in seq:  # Ensure the same item is not repeatedly added\n",
        "                new_seq = seq + (item,)\n",
        "                if len(new_seq) == length:\n",
        "                    candidates.add(new_seq)\n",
        "    return candidates\n",
        "\n",
        "# Function to count support of each candidate sequence\n",
        "def count_support(candidates, transactions):\n",
        "    support_counts = defaultdict(int)\n",
        "    num_candidates = len(candidates)\n",
        "    for i, candidate in enumerate(candidates, 1):\n",
        "        for transaction in transactions:\n",
        "            if all(item in transaction for item in candidate):\n",
        "                support_counts[candidate] += 1\n",
        "        if i % 100 == 0 or i == num_candidates:\n",
        "            print(f\"Progress: {i}/{num_candidates}\")\n",
        "    return support_counts\n",
        "\n",
        "# Function to prune candidates that do not meet the minimum support threshold\n",
        "def prune_candidates(support_counts, min_support):\n",
        "    return {seq: count for seq, count in support_counts.items() if count >= min_support}\n",
        "\n",
        "# Function to implement the SPADE algorithm\n",
        "def spade(transactions, min_support):\n",
        "    sequences = {(): len(transactions)}\n",
        "    length = 1\n",
        "    while True:\n",
        "        print(f\"Generating candidates of length {length}...\")\n",
        "        candidates = generate_candidates(sequences.keys(), length)\n",
        "        print(f\"Number of candidates: {len(candidates)}\")\n",
        "\n",
        "        print(\"Counting support for candidates...\")\n",
        "        support_counts = count_support(candidates, transactions)\n",
        "        total_support = sum(support_counts.values())\n",
        "        print(f\"Total support count for length {length}: {total_support}\")\n",
        "\n",
        "        print(\"Pruning candidates...\")\n",
        "        pruned_candidates = prune_candidates(support_counts, min_support)\n",
        "        print(f\"Pruned candidates: {pruned_candidates}\")\n",
        "\n",
        "        if not pruned_candidates:\n",
        "            break\n",
        "        sequences.update(pruned_candidates)\n",
        "        length += 1\n",
        "    return sorted(sequences.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Prepare transactions for SPADE algorithm\n",
        "transactions = order_products.groupby('user_id')['product_id'].apply(list).tolist()\n",
        "\n",
        "# Define minimum support threshold\n",
        "min_support = 0.2 * len(transactions)  # Adjusted to a lower value\n",
        "\n",
        "# Run SPADE algorithm\n",
        "frequent_patterns = spade(transactions, min_support)\n",
        "\n",
        "# Output the frequent patterns, excluding the empty sequence\n",
        "frequent_patterns = [pattern for pattern in frequent_patterns if pattern[0]]\n",
        "print(frequent_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "lzHOwYGnBGEr",
        "outputId": "c0703769-0548-434f-e5d1-422154b102b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating candidates of length 1...\n",
            "Number of candidates: 47975\n",
            "Counting support for candidates...\n",
            "Progress: 100/47975\n",
            "Progress: 200/47975\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-961e74dae966>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Run SPADE algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mfrequent_patterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspade\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Output the frequent patterns, excluding the empty sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-961e74dae966>\u001b[0m in \u001b[0;36mspade\u001b[0;34m(transactions, min_support)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Counting support for candidates...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msupport_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtotal_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total support count for length {length}: {total_support}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-961e74dae966>\u001b[0m in \u001b[0;36mcount_support\u001b[0;34m(candidates, transactions)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0msupport_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-961e74dae966>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0msupport_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}